# Installation of Perturbo
Installing Perturbo can be complicated due to the fact that it depends on other packages, such as Quantum Espresso, HDF5, LAPACK, etc.
Therefore, there are 2 scenarios for installing our package - from scratch (which was covered on the first day in the first tutorial) and using containers. During the workshop you will use the second method, so now we will take a closer look at it, as well as discuss the testing procedure for Perturbo.

## Usage of containers

It is possible to run perturbo faster and easier if you use soft called Docker. This will not be a universal solution, but it will allow you to get acquainted with the functionality of the package, as well as to run programs that are not computationally intensive.

### About Docker and containers
Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers. 

So Docker is just the name of the software that allows you to use things called containers. Accordingly, we need to understand what containers are. 
![Containers vs. virtual machine](https://github.com/perturbo-code/perturbo-workshop-2023/blob/main/Hands-on1/images/docker_def.png)

Let's consider a container versus a virtual machine. In the latter case, we have several separate operating systems running, managed by a hypervisor. In this case, each OS is independent and exists on its own, they are completely separated from each other.

A container, on the other hand, uses the kernel of the host operating system, and on its basis runs a "micro-OS", inside which there are only a few necessary applications. This allows you to get an environment with applications installed in it and start using it quite quickly without large memory and computational costs.

For example, if we're talking about `perturbo/perturbo:gcc_openmp`, this image (more on that below) consists of:

1. Ubuntu shell
2. The built gcc compiler
3. Some supplementary staff (`vim`, `unzip`, etc.)
3. the HDF5 and Quantum Espresso packages
4. Perturbo package

![perturbo/perturbo:gcc](https://github.com/perturbo-code/perturbo-workshop-2023/blob/main/Hands-on1/images/perturbo_gcc.png)

Accordingly, by running a container of this image (more on this below) on any computer running [Docker](https://www.docker.com) or its analogs (such as [Podman](https://podman.io)), you will be able to perform calculations using `Perturbo`, avoiding compilation. That's the point of containerization - to create an image ready to use.

### Basic concepts:

1. Image is a "mini-OS" that will be used. It is these images that are hosted on the [docker hub](https://hub.docker.com), where you can find images for many different applications. That's where the name of our images comes from. In this case, what comes before the slash is the name of the repository owner, after the slash is the name of the repository itself, and after the colon is the image tag. So the name [**perturbo/perturbo:gcc_openmp**](https://hub.docker.com/repository/docker/perturbo/perturbo/general) can be understood as "The image of the perturbo user from the perturbo repository with the *gcc_openmp* tag" 
2. Container - is an instance of a "virtual machine" that is created from an existing image. It is in the created container that your work is done. The relationship between an image and a container is similar to the relationship between a class and its instance. The class defines general characteristics, while we work with instances of the class. Here the essence is the same.

While a container is simply an instance built from an image, the image itself can be used in different ways. It can be used to create new containers as well as to create new images. For example, the Perturbo image is built in two stages - first, the supplementary [Docker Images](https://hub.docker.com/repository/docker/perturbo/perturbo_suppl/general) (containing all the supplementary libraries). The supplementary images take [Ubuntu](https://hub.docker.com/_/ubuntu) images as their base.

3. Volumes - are the preferred mechanism for persisting data generated by and used by Docker containers. The idea is that when each container is created, a corresponding volume is created. By default, such volumes are deleted when the container itself is deleted. This is inconvenient if we need to save some files from the container. Below is how to avoid this.

Visit https://docker-curriculum.com for more information.

### Run the Docker on your computer 
If you want to use builded images on your computer, you will need to follow these steps:

1. Install the [Docker](https://www.docker.com) application on your computer. This program should always be running, it is the Docker daemons that allow containers to run. If you have everything installed and running correctly, invoke the `docker` command in the terminal. You should then get the following system response:
   ```bash
   docker

   Usage:  docker [OPTIONS] COMMAND

   A self-sufficient runtime for containers

   Common Commands:
     run         Create and run a new container from an image
     exec        Execute a command in a running container
     ps          List containers
     build       Build an image from a Dockerfile
     pull        Download an image from a registry
     push        Upload an image to a registry
     images      List images
     login       Log in to a registry
     logout      Log out from a registry
     search      Search Docker Hub for images
     version     Show the Docker version information
     info        Display system-wide information

   Management Commands:
     builder     Manage builds
     buildx*     Docker Buildx (Docker Inc., v0.11.2-desktop.4)
     compose*    Docker Compose (Docker Inc., v2.21.0-desktop.1)
     container   Manage containers
     context     Manage contexts
     dev*        Docker Dev Environments (Docker Inc., v0.1.0)
     extension*  Manages Docker extensions (Docker Inc., v0.2.20)
     image       Manage images
     init*       Creates Docker-related starter files for your project (Docker Inc., v0.1.0-beta.7)
     manifest    Manage Docker image manifests and manifest lists
     network     Manage networks
     plugin      Manage plugins
     sbom*       View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)
     scan*       Docker Scan (Docker Inc., v0.26.0)
     scout*      Command line tool for Docker Scout (Docker Inc., 0.24.1)
     system      Manage Docker
     trust       Manage trust on Docker images
     volume      Manage volumes

   Swarm Commands:
     swarm       Manage Swarm

   Commands:
     attach      Attach local standard input, output, and error streams to a running container
     commit      Create a new image from a container's changes
     cp          Copy files/folders between a container and the local filesystem
     create      Create a new container
     diff        Inspect changes to files or directories on a container's filesystem
     events      Get real time events from the server
     export      Export a container's filesystem as a tar archive
     history     Show the history of an image
     import      Import the contents from a tarball to create a filesystem image
     inspect     Return low-level information on Docker objects
     kill        Kill one or more running containers
     load        Load an image from a tar archive or STDIN
     logs        Fetch the logs of a container
     pause       Pause all processes within one or more containers
     port        List port mappings or a specific mapping for the container
     rename      Rename a container
     restart     Restart one or more containers
     rm          Remove one or more containers
     rmi         Remove one or more images
     save        Save one or more images to a tar archive (streamed to STDOUT by default)
     start       Start one or more stopped containers
     stats       Display a live stream of container(s) resource usage statistics
     stop        Stop one or more running containers
     tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
     top         Display the running processes of a container
     unpause     Unpause all processes within one or more containers
     update      Update configuration of one or more containers
     wait        Block until one or more containers stop, then print their exit codes

   Global Options:
         --config string      Location of client config files (default
                              "/Users/kliavinekss/.docker")
     -c, --context string     Name of the context to use to connect to the
                              daemon (overrides DOCKER_HOST env var and
                              default context set with "docker context use")
     -D, --debug              Enable debug mode
     -H, --host list          Daemon socket to connect to
     -l, --log-level string   Set the logging level ("debug", "info",
                              "warn", "error", "fatal") (default "info")
         --tls                Use TLS; implied by --tlsverify
         --tlscacert string   Trust certs signed only by this CA (default
                              "/Users/kliavinekss/.docker/ca.pem")
         --tlscert string     Path to TLS certificate file (default
                              "/Users/kliavinekss/.docker/cert.pem")
         --tlskey string      Path to TLS key file (default
                              "/Users/kliavinekss/.docker/key.pem")
         --tlsverify          Use TLS and verify the remote
     -v, --version            Print version information and quit

   Run 'docker COMMAND --help' for more information on a command.

   For more help on how to use Docker, head to https://docs.docker.com/go/guides/
   ```
   Also, you can check that images do you have on your computer right now:
   ```bash
   docker images
   ```
   It's expected to obtain something like that:
   ```bash
   REPOSITORY          TAG                IMAGE ID       CREATED        SIZE
   ```
   Now you don't have any images. If you want to check what containers do you have, you need to run the command `docker ps -a`, where `-a` means all containers. You'll see the following response:
   ```bash
   CONTAINER ID   IMAGE                           COMMAND       CREATED       STATUS                     PORTS    NAMES
   ```
   Now you don't have any containers.
2. Clone the Image from the [Docker Hub of the Perturbo](https://hub.docker.com/repository/docker/perturbo/perturbo/general). You can find the command for pulling the images on the tab **Tags**. For example, for **gcc_openmp** case it would be:
	```bash
	docker pull perturbo/perturbo:gcc_openmp
	```
	You can use this container because it is light enough and it is also especially well suited for computers with ARM64 processors (Macs with M1/M2). In case of computers with Intel processors, a possible solution is to use the *ifort_openmp* container, which supports parallelization.
3. Let's verify that you do indeed have a new image:
	```bash
	docker images
	```
	It's expected to obtain something like that:
	```bash
	REPOSITORY          TAG                IMAGE ID       CREATED        SIZE
	perturbo/perturbo   gcc_openmp         b68664b8a5f9   5 hours ago    4.38GB
	```

3. Run the following command:
	```bash
	docker run -v name_of_your_work_folder:/home/user/run/workshop -h perturbocker --rm --name perturbo perturbo/perturbo:tag
	```
This command has the following meaning:
1. `-v` - V for ~~Vendetta~~ Volumes, which we talked about earlier. To connect a folder on your primary OS to a folder inside the container, specify the name of the folder on your computer, and after the colon, what the same volume inside the container will be called. In this case, the changes that will happen to the volume inside the container will be reflected in your OS and vice versa. This allows you to not only transfer input files to the container, but also to save all output-files after the container is finished and the container itself is deleted. Below we take a look at how this works; 

2. `-h perturbocker` - is the hostname of the container. By default, it is the same as the container ID, which may not be particularly informative or readable. So we give it a specific name;
3. `--rm` - deletes the container after its use is finished. Made to save memory. If it is important for you to save the container itself (for example, if you have installed any packages there), this option should be removed, and the container should be started using [`docker start`](https://docs.docker.com/engine/reference/commandline/start/) in the future. 
4. `--name` - the name that the container will receive. During run (and, if the container is not deleted, during storage) it can be referred to by this name. 

You need to change two parameters:

1. The names of your volume;
2. The name of the image itself - instead of `tag` specify the tag of the image you want to use as a basis for creating the container.

Full list of the command line options is provided on the [offical page](https://docs.docker.com/engine/reference/commandline/run/).

Now we can run the container aaand... nothing will happen. The point is that inside the container itself, it has a single action prescribed to it - to run bash. If we run it without interactive mode, it will run bash and that will be the end of it. That doesn't work for us - we're interested in running inside the container. That's why we need to run another parameter  `-it` (means interactive):

```bash
docker run -v name_of_your_work_folder:/home/user/run/workshop -h perturbocker -it --rm --name perturbo perturbo/perturbo:tag
```


Now you're inside the container, congratulations! 

We can check, that we actually run the container. Call in the new Terminal window `docker ps -a`, and you'll obtain:
```bash 
CONTAINER ID   IMAGE                           COMMAND       CREATED         STATUS                     PORTS     NAMES
58dfcc3ac8cc   perturbo/perturbo:gcc_openmp    "/bin/bash"   6 seconds ago   Up 3 seconds                         perturbo
```

If you want to use perturbo, all you have to do is type in the terminal

```bash 
perturbo.x 
```

And you will see the program start up. Similarly with Quantum Espresso executables.

Let's now go back to how volumes work. Create a test_volumes file in our folder on the Host OS:
```bash
touch test_volumes
```
Now let's check inside the container to see how our folder has changed:
```bash
cd workshop/
ls

Hands-on1  Hands-on2  Hands-on3  Hands-on4  README.md  Tutorial2  Tutorial3  Tutorial4  test_volumes

```
We see the created file. Now let's rename it in the container:
```bash
mv test_volume test_volume_2
```

We can check that in our Host OS the file has also been renamed. That is, we can change files inside the container and inside the Host OS at the same time.

Now you are ready for the usage of Perturbo in the container form!


## Testsuite

Even in case of using a container, there may be problems with using the code due to different architectures of image author's processors and yours, wrong compilation options from the beginning and so on. In the case of installing from a scratch, the problem becomes even more serious, since errors can occur at many stages. Accordingly, you need a powerful tool that allows you to perform full testing of the installed package. Such a tool is [Testsuite](https://perturbopy.readthedocs.io/en/latest/testsuite.html), distributed in the Perturbopy package.

### General description

As you discissed yesterday, Perturbo package provides two executables: 

1. `qe2pert.x` to postprocess the preliminary DFT, DFPT, and Wannier90 calculations and to compute the electron-phonon matrix elements in the Wannier basis stored in the `prefix_epr.h5` file.

2. `perturbo.x` - the core executable of Perturbo package performing transport calculations, ultrafast dynamics, etc. 

For more details, please read this [Perturbo page](https://perturbo-code.github.io/mydoc_features.html>).

To test this executables, we provide a testsuite within the `Perturbopy` package. We recommend to run the testsuite:

* to verify that the code runs correctly after download and installation;
* if some modifications to the source code have been made;
* if you would like to contribute to the Perturbo public version (in this situation, new test cases are also required).

### Running testsuite

#### Basic run
To run testsuite you need a folder with input files, reference files, configuration files, etc. You can find the example of this folder in the `/opt/q-e-qe-7.2/perturbo/tests` folder.  We will use these tests today, but in general you can (and in some cases even should) write your own tests.

#### Testing `perturbo.x` only

If you plan to use (or you did modifications only to) the `perturbo.x` executable, the testsuite will automatically run `perturbo.x` for several materials and calculation modes and check that the results obtained with the new executable are the same as the reference.

To test the `perturbo.x` executable you need to make the configuration file. As an example, in the *tests/config_machine* folder, you can take the *config_machine_perturbo.yml* file. This file contains basic information about running tesuite for `perturbo.x`.

1. Copy the template YAML file inside the */opt/q-e-qe-7.2/perturbo/tests/config_machine* folder:

```bash
   cd config_machine
   cp config_machine_perturbo.yml config_machine.yml
```
By default, the file named *config_machine.yml* is the one called by the program. If you want to use a file with a different name, you can use one of the [command-line options](https://perturbopy.readthedocs.io/en/latest/testsuite.html#parameterization-of-testsuite).

2. Make changes to the configuration file. By default, the *config_machine_perturbo.yml* file is as follows:

```bash
    PERT_SCRATCH: tmp
    prel_coms:
        - module load perturbo
        - export OMP_NUM_THREADS=8
    comp_info:
        perturbo:
            exec: srun -n 8 perturbo.x -npools 8
```
Below the meaning of each of the blocks:

* `PERT_SCRATCH` is the address of the folder where the auxiliary files in the tests will be located. 
* `prel_coms` is a set of commands to be executed **before** the `perturbo.x` run. This could be loading packages, specifying any environment variables, etc. Enter every command as a separate line preceded by a hyphen, respecting the file indentation. In our case, we need to save only second line of `prel_coms` in case of usage container with openmp, of we can delete this commands at all.
* `comp_info` - this block contains information about the `perturbo.x` computation. It has the `exec` field that specifies the run command taking into account the parallelization and other machine specifics. In this example, `perturbo.x` will be ran with the SLURM srun command using 8 MPI tasks. 

We will use containers without MPI, so our final *config_machine_perturbo.yml* file can looks in the following way:

```bash
    PERT_SCRATCH: tmp
    prel_coms:
        - export OMP_NUM_THREADS=8
    comp_info:
        perturbo:
            exec: perturbo.x -npools 8
```


Once, the `config_machine.yml` is set up, navigate back to the `tests` folder and run:

```bash
   ./run_tests.py -s
```
This script will automatically load and run all the tests from the `perturbopy` package and show you all intermediate steps.

By default, in the case of successful run of all tests one will see **n passed** as the final line of the output, where **n** is the number of tests. You will also see that some tests have been skipped. This is fine, because the tests for `qe2pert.x` are skipped if it's not specified.

If all tests are passed, the `PERT_SCRATCH/perturbo` directory will be empty after the `./run_tests.py` execution. In the case of a failure of one or more tests, the corresponding test folder(s) kept in the `PERT_SCRATH/perturbo` directory. 

#### Testing `qe2pert.x` and `perturbo.x`

If you would like to test both `qe2pert.x` and `perturbo.x` executables, which is recommended after a compilation of the code from scratch or if you have done modifications to `qe2pert.x`, 
the testsuite will consist of three parts:

1. Test `perturbo.x` (similar to the section above).
2. Perform preliminary *ab initio* calculations from scratch (DFT, DFPT, Wannier90, more on that [here](https://perturbo-code.github.io/mydoc_qe2pert.html), and use `qe2pert.x` to generate new `prefix_epr.h5` files.
3. Run part of the calculations from step 1 again, and compare the outputs of `perturbo.x` produced with the new `prefix_epr.h5` files. 

The step 3 is necessary to test the `qe2pert.x` executable because one cannot compare the `prefix_epr.h5` files to the reference ones directly due to gauge freedom. Therefore, we need to use `perturbo.x`, whose correctness we confirmed in step 1, to use it to determine whether `qe2pert.x` worked correctly. Since there is no need to check all the `perturbo.x` tests to verify the work of `qe2pert.x`, at the third stage we run only three claculation modes of Perturbo for each `prefix_epr.h5` file: `phdisp`, `ephmat` and `bands`. If these three tests pass, it means that `qe2pert.x` works correctly.

By default, the `qe2pert.x` testing is disabled as it is very time consuming (can take several hours in comparison with several minutes in case of `perturbo.x`) and requires a user to specify the Quantum Espresso and Wannier90 executables.

Similarly to `perturbo.x`-only tests, the user needs to make a new the *config_machine/config_machine.yml* file, but this time the file should include more information. As a reference, you can take file  *config_machine_qe2pert.yaml*

1. Make your copy of the template YAML file:

```bash 
    cd config_machine
    rm config_machine.yml
    cp config_machine_qe2pert.yml config_machine.yml
```

2. Update the *config_machine.yml*  file for your specific case. By default,  the file has the following structure:

```bash 

    PERT_SCRATCH: tmp
    prel_coms:
        - module load perturbo
        - module load qe
    comp_info:
        scf: 
            exec: srun -n 64 pw.x -npools 8
        phonon:
            exec: srun -n 64 ph.x -npools 8
        nscf:
            exec: srun -n 64 pw.x -npools 8
        wannier90:
            exec: srun -n 2 wannier90.x
        pw2wannier90:
            exec: srun -n 1 pw2wannier90.x
        qe2pert:
            prel_coms:
                - export OMP_NUM_THREADS=8
            exec: srun -n 8 qe2pert -npools 8
        perturbo:
            prel_coms:
                - export OMP_NUM_THREADS=8
            exec: srun -n 8 perturbo.x -npools 8
```
			
where `PERT_SCRATCH` and `prel_coms` are similar to the `perturbo.x`-only testing. Please note that the `prel_coms` (the top one) will be executed before each of the stages. `comp_info` now includes the run commands for each of the stages. If there are preliminary commands to be run *only* before a specific stage, this can be specified by the `prel_coms` field within the stage (see examples for the `qe2pert` `perturbo` runs in the YAML file).

For our case, we can define the *config_machine.yml* in the following way:

```bash 

    PERT_SCRATCH: tmp
    comp_info:
        scf: 
            exec: pw.x
        phonon:
            exec: ph.x
        nscf:
            exec: pw.x
        wannier90:
            exec: wannier90.x
        pw2wannier90:
            exec: pw2wannier90.x
        qe2pert:
            prel_coms:
                - export OMP_NUM_THREADS=8
            exec: qe2pert -npools 8
        perturbo:
            prel_coms:
                - export OMP_NUM_THREADS=8
            exec: perturbo.x -npools 8
```

To enable the tests of `qe2pert.x`, activate the `--run_qe2pert` option. Also we'll take only one `epr`-file out of six because of the time complexity (even in this case it would take ~20 minutes):

```bash
   ./run_tests.py --run_qe2pert --epr epr4 -s
```

When the tests are successful, you'll be confident that your perturbo is working well and you can move on to the next hands-on sessions.
